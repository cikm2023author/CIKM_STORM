{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b8985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199e7144",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_severe_df = pd.read_csv('severe_weather_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e17d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/41336756/find-the-closest-latitude-and-longitude\n",
    "from math import cos, asin, sqrt\n",
    "\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    p = 0.017453292519943295\n",
    "    hav = 0.5 - cos((lat2-lat1)*p)/2 + cos(lat1*p)*cos(lat2*p) * (1-cos((lon2-lon1)*p)) / 2\n",
    "    return 12742 * asin(sqrt(hav)) # 12742 = earth diameter km\n",
    "\n",
    "# data is a list of dicts w/ 'lat', 'lon', and 'lct' (location number)\n",
    "# v is a single dict w/ 'lat', 'lon'\n",
    "def closest(data, v):\n",
    "    mindist = 100000\n",
    "    beststore = data[0]\n",
    "    for datum in data:\n",
    "        dist = distance(v['lat'],v['lon'],datum['lat'],datum['lon'])\n",
    "        if dist < mindist:\n",
    "            mindist = dist\n",
    "            beststore = datum\n",
    "    return beststore, mindist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de2ade3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a list of store locations along with longitude and latitude.\n",
    "# stores identified by location number, column lct_nbr\n",
    "# latitude and longitude given by columns ltd_msr, lng_msr\n",
    "store_df = pd.read_csv('path_to_your_stores_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a488a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lctdict = []\n",
    "for lct in set(store_df['lct_nbr']):\n",
    "    lct_row = store_df[store_df['lct_nbr'] == lct].iloc[0]\n",
    "    lctdict += [{'lat': lct_row['ltd_msr'], 'lon': lct_row['lng_msr'], 'lct': lct}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b3377e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "import tqdm\n",
    "import numpy as np\n",
    "geolocator = Nominatim(user_agent='myapplication')\n",
    "\n",
    "# associate each weather event with a particular store location\n",
    "failed = []\n",
    "raw_severe_df['lct_nbr'] = [-1] * raw_severe_df.shape[0]\n",
    "raw_severe_df['dist'] = [100000] * raw_severe_df.shape[0]\n",
    "for iidx in tqdm.tqdm(range(raw_severe_df.shape[0])):\n",
    "    row = raw_severe_df.iloc[iidx]\n",
    "    if np.isnan(row['begin_lat']) or np.isnan(row['begin_lon']):\n",
    "        if row['begin_location'] is None:\n",
    "            try:\n",
    "                # get last word of county name, eg. Litchfield from \"Southern Litchfield\"\n",
    "                location = geolocator.geocode(row['cz_name'].split(' ')[-1] + ' ' + row['state'])\n",
    "            except:\n",
    "                failed += [iidx]\n",
    "                continue\n",
    "        else:\n",
    "            try:\n",
    "                location = geolocator.geocode(row['begin_location'] + ' ' + row['state'])            \n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "        try:\n",
    "            v = {'lat': location.latitude, 'lon': location.longitude}\n",
    "        except:\n",
    "            failed += [iidx]\n",
    "            continue\n",
    "    else:    \n",
    "        v = {'lat': row['begin_lat'], 'lon': row['begin_lon']}\n",
    "    closest_store, dist = closest(lctdict, v)\n",
    "    raw_severe_df['lct_nbr'].iat[iidx] = closest_store['lct']\n",
    "    raw_severe_df['dist'].iat[iidx] = dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569be192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter severe weather events so there is only one per day per location\n",
    "from collections import defaultdict\n",
    "maxit = -1\n",
    "ccounts = defaultdict(int)\n",
    "todrop = set()\n",
    "for iidx in tqdm.tqdm(range(raw_severe_df.shape[0])):\n",
    "    row = raw_severe_df.iloc[iidx]\n",
    "    lct_date_df = raw_severe_df[(raw_severe_df['lct_nbr'] == row['lct_nbr']) & (raw_severe_df['begin_yearmonth'] == row['begin_yearmonth']) & (raw_severe_df['begin_day'] == row['begin_day'])]\n",
    "    mindist = lct_date_df['dist'].min()\n",
    "    final_ld_df = lct_date_df[lct_date_df['dist'] == mindist]\n",
    "    mintime = final_ld_df['begin_time'].min()\n",
    "    final_ld_df = final_ld_df[final_ld_df['begin_time'] == mintime]\n",
    "    if final_ld_df.shape[0] > maxit:\n",
    "        maxit = final_ld_df.shape[0]\n",
    "        itit = final_ld_df\n",
    "    if final_ld_df.shape[0] > 1:\n",
    "        ccounts[(row['lct_nbr'], row['begin_yearmonth'], row['begin_day'])] += 1        \n",
    "\n",
    "    # if we have filtered by mindist and min time and there are still multiple events, choose one at random\n",
    "    final_ld_df = final_ld_df.sample(n = 1)    \n",
    "\n",
    "    diffset = set(lct_date_df.index).difference(set(final_ld_df.index))\n",
    "    todrop = todrop.union(diffset)\n",
    "\n",
    "filtered_raw_df = raw_severe_df.drop(todrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d0079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in date column to match with interactions dataset feed_date\n",
    "filtered_raw_df['date'] = [\"\"] * filtered_raw_df.shape[0]\n",
    "for iidx in tqdm.tqdm(range(filtered_raw_df.shape[0])):\n",
    "    row = filtered_raw_df.iloc[iidx]\n",
    "    dateresult = str(row['begin_yearmonth'])[:4] + \"-\" + str(row['begin_yearmonth'])[4:6] + '-' + f\"{row['begin_day']:02}\"\n",
    "    filtered_raw_df['date'].iat[iidx] = dateresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbb9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each location, fill in all calendar days with the number of days since a severe weather event\n",
    "import datetime\n",
    "filtered_raw_df['days_since'] = [0] * filtered_raw_df.shape[0]\n",
    "new_rows = pd.DataFrame(columns=filtered_raw_df.columns)\n",
    "mindate = min(filtered_raw_df['date'])\n",
    "maxdate = max(filtered_raw_df['date'])\n",
    "for lct_nbr in tqdm.tqdm(set(filtered_raw_df['lct_nbr'])):\n",
    "    last_row_found = False\n",
    "    last_row = None\n",
    "    for ddate in pd.date_range(mindate,maxdate,freq='d'):\n",
    "        datestr = str(ddate)[:10]\n",
    "        row = filtered_raw_df[(filtered_raw_df['lct_nbr'] == lct_nbr) & (filtered_raw_df['date'] == datestr)]\n",
    "        assert(row.shape[0] == 0 or row.shape[0] == 1)        \n",
    "\n",
    "        # Date is present in df\n",
    "        if row.shape[0] == 1:\n",
    "            last_row_found = True\n",
    "            last_row = row\n",
    "            continue        \n",
    "\n",
    "        # date is not present in df\n",
    "        # fill in missing date with last df\n",
    "        if last_row_found:\n",
    "            new_row = last_row.copy()\n",
    "            new_row['date'] = datestr\n",
    "            new_row['days_since'] = datetime.datetime.strptime(datestr, \"%Y-%m-%d\").date() - datetime.datetime.strptime(last_row['date'].item(), \"%Y-%m-%d\").date()\n",
    "            #new_rows = new_rows.append(new_row)\n",
    "            new_rows = pd.concat([new_rows, new_row], ignore_index=True)\n",
    " \n",
    "#new_rows = new_rows.append(filtered_raw_df, ignore_index=True)\n",
    "new_rows = pd.concat([new_rows, filtered_raw_df], ignore_index=True)\n",
    "new_rows.sort_values(by=['lct_nbr','date'], ascending=True, inplace=True)\n",
    "new_days_since = new_rows['days_since']\n",
    "for iidx in tqdm.tqdm(range(new_rows.shape[0])):\n",
    "    if not type(new_rows['days_since'].iloc[iidx]) is int:\n",
    "        new_days_since.iat[iidx] = new_rows['days_since'].iloc[iidx].days\n",
    "new_rows['days_since'] = new_days_since"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845712f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_raw_df = new_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58388b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a list of interaction data.\n",
    "# Customers have specified preferred/local store, which we use to match\n",
    "# interaction df must include columns: 'store_nbr' (preferred/local store) and 'feed_date' (interaction date).\n",
    "# store_nbr should match format of filtered_raw_df 'lct_nbr' column\n",
    "# feed_date should match format of filtered_raw_df 'date' column\n",
    "store_df = pd.read_csv('path_to_your_interactions_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86eddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge store/weather dataset with interaction data\n",
    "bigdf = interaction_df.merge(filtered_raw_df, how='left', left_on=['store_nbr', 'feed_date'], right_on=['lct_nbr', 'date'], suffixes=('_interactions', '_weather'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b108c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
